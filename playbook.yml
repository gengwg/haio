---
# Hadoop install

- hosts: all 
  #user: vagrant 
  #sudo: true
  tasks:

  # general
  - name: upgrade all packages
    yum: name=* state=latest
    become: true

  - name: install the 'Development tools' package group
    yum:
      name: "@Development tools"
      state: present
    become: true

  - name: install epel repo 
    yum: name=epel-release state=present
    become: true

  - name: install useful tools 
    yum: name={{ item }} state=present
    with_items:
      - python-pip
      - vim
      - net-tools
      - bind-utils
    become: true

  # hadoop
  - name: install wget 
    yum: name=wget state=present
    become: true

  - name: install openjdk 1.8.0
    yum: name=java state=present
    become: true

  - name: check if hadoop is already downloaded 
    #command: /usr/bin/test -e /home/vagrant/hadoop-2.7.3.tar.gz
    #ignore_errors: True
    stat:
      path: /home/vagrant/hadoop-2.7.3.tar.gz
    register: hadoop_download

  - name: download hadoop 2.7.3 
    get_url:
       url=http://apache.claz.org/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz dest=/home/vagrant 
    #when: hadoop_exists.rc != 0 
    #when: hadoop_exists.stat.exists == False
    when: not hadoop_download.stat.exists

  - name: check hadoop directory existence
    stat: path=/opt/hadoop-2.7.3
    register: hadoop_dir  

  - name: extract hadoop
    unarchive: src=/home/vagrant/hadoop-2.7.3.tar.gz dest=/opt copy=no
    when: not hadoop_dir.stat.exists
    become: true

  - name: create symbolic link
    file: src=/opt/hadoop-2.7.3 dest=/opt/hadoop state=link
    become: true

  - name: add the path of the Hadoop program to the PATH environment variable 
    shell: echo "export PATH=/opt/hadoop-2.7.3/bin:$PATH" | sudo tee -a /etc/profile && source /etc/profile
    become: true

  - name: add hadoop user
    user:    
      name: hadoop
      generate_ssh_key: yes
      ssh_key_bits: 2048
      ssh_key_file: .ssh/id_rsa
    become: true

  - name: chown hadoop dir
    shell: chown -R -H hadoop:hadoop /opt/hadoop
    become: true

  - name: run ssh-keyscan to add localhost to known_hosts
    shell: ssh-keyscan -t rsa {{ item }}  >> /etc/ssh/ssh_known_hosts
    with_items:
      - localhost
      - 0.0.0.0
    become: true

  - name: add the authorized keys
    shell: cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys && chmod 0600 ~/.ssh/authorized_keys
    become: true
    become_user: hadoop

  - name: copy .bashrc
    copy: src=bashrc dest=/home/hadoop/.bashrc
    become: true
    become_user: hadoop

  - name: hadoop conf core-site
    template: src={{ item.src }} dest={{ item.dest }}
    with_items: 
      - { src: 'hadoop_conf/core-site.xml', dest: '/opt/hadoop/etc/hadoop' }
      - { src: 'hadoop_conf/hdfs-site.xml', dest: '/opt/hadoop/etc/hadoop' }
      - { src: 'hadoop_conf/mapred-site.xml', dest: '/opt/hadoop/etc/hadoop' }
      - { src: 'hadoop_conf/yarn-site.xml', dest: '/opt/hadoop/etc/hadoop' }
      - { src: 'hadoop_conf/hadoop-env.sh', dest: '/opt/hadoop/etc/hadoop' }
    become: true
    become_user: hadoop

  - name: check hadoop namenode directory existence
    stat: path=/home/hadoop/hadoopdata/hdfs/namenode
    register: namenode_dir  
    become: true
    become_user: hadoop

  - name: set up namenode
    command: /opt/hadoop/bin/hdfs namenode -format -nonInteractive
    ignore_errors: True
    when: not namenode_dir.stat.exists
    become: true
    become_user: hadoop

  - name: start hdfs
    command: /opt/hadoop/sbin/start-dfs.sh
    ignore_errors: True
    become: true
    become_user: hadoop

  - name: start resource manager and node manager
    command: /opt/hadoop/sbin/start-yarn.sh
    ignore_errors: True
    become: true
    become_user: hadoop


